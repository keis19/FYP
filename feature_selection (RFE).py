# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XMIPEPuzvlNck5VwO1tbzUGatZdD_35U
"""

import matplotlib.pyplot as plt
from matplotlib.pyplot import figure
from google.colab import files
import numpy as np
import pandas as pd
from pandas.plotting import parallel_coordinates

from collections import Counter
from datetime import datetime

# Visualization
import seaborn as sns
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots

# Model
import sklearn
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.preprocessing import OrdinalEncoder

from sklearn.feature_selection import chi2
from imblearn.over_sampling import SMOTE
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import average_precision_score, precision_recall_curve
from sklearn.metrics import auc, plot_precision_recall_curve

# , OneHotEncoder
# from sklearn.metrics import roc_auc_score
# from sklearn.metrics import accuracy_score
# from sklearn.cluster import KMeans
# from scipy.stats import skew
# import plotly.io as pio
# from pathlib import Path

from google.colab import drive
drive.mount('/content/gdrive')

df_train= pd.read_csv("gdrive/MyDrive/fraudTrain.csv")
df_train = df_train.drop(df_train.columns[0], axis=1)

df_train.head()

df_train.rename(columns={"trans_date_trans_time":"transaction_time",
                         "cc_num":"credit_card_number",
                         "amt":"amount(usd)",
                         "trans_num":"transaction_id"},
                inplace=True)

df_train["transaction_time"] = pd.to_datetime(df_train["transaction_time"], infer_datetime_format=True)
df_train["dob"] = pd.to_datetime(df_train["dob"], infer_datetime_format=True)

# Apply function utcfromtimestamp and drop column unix_time
df_train['time'] = df_train['unix_time'].apply(datetime.utcfromtimestamp)
df_train.drop('unix_time', axis=1)

# Add column hour of day
df_train['hour_of_day'] = df_train.time.dt.hour

# Change dtypes
df_train.credit_card_number = df_train.credit_card_number.astype('category')
df_train.is_fraud = df_train.is_fraud.astype('category')
df_train.hour_of_day = df_train.hour_of_day.astype('category')

np.round(df_train.describe(), 2)

df_train.columns

df_train.dtypes

# features = ['transaction_id', 'hour_of_day', 'category', 'amount(usd)', 'merchant', 'job', 'credit_card_number', 'city_pop']
features = ['credit_card_number', 'merchant', 'category',
       'amount(usd)', 'city_pop', 'job', 'transaction_id','hour_of_day' ,'zip', 'unix_time', 'merch_lat', 'merch_long', 'lat', 'long']


X = df_train[features].set_index("transaction_id")
y = df_train['is_fraud']

print('X shape:{}\ny shape:{}'.format(X.shape,y.shape))


enc = OrdinalEncoder(dtype=np.int64)
enc.fit(X.loc[:,['category','merchant','job']])

X.loc[:, ['category','merchant','job']] = enc.transform(X[['category','merchant','job']])

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y)
print('X_train shape:{}\ny_train shape:{}'.format(X_train.shape,y_train.shape))
print('X_test shape:{}\ny_test shape:{}'.format(X_test.shape,y_test.shape))

from imblearn.under_sampling import RandomUnderSampler
#SMOTE
smt = SMOTE(sampling_strategy=0.1)
X_train_smote, y_train_smote = smt.fit_resample(X_train.astype('float'), y_train)
#Under Sampling + SMOTE
rus = RandomUnderSampler(sampling_strategy=0.5)
X_train_smote_rus, y_train_smote_rus = rus.fit_resample(X_train_smote, y_train_smote)
print("Before SMOTE:", Counter(y_train))
print("After SMOTE:", Counter(y_train_smote))
print("After SMOTE + Random Under-sampling:", Counter(y_train_smote_rus))

print('Decision Tree WITH RFE')

from sklearn.metrics import roc_auc_score
from sklearn.feature_selection import RFE

rfe= RFE(estimator=DecisionTreeClassifier(), n_features_to_select=5)
rfe.fit(X_train, y_train)
y_pred = rfe.predict(X_test)
print(classification_report(y_test,y_pred))

# Data to plot precision - recall curve
precision, recall, thresholds = precision_recall_curve(y_test, y_pred)
# Use AUC function to calculate the area under the curve of precision recall curve
auc_precision_recall = auc(recall, precision)
plt.plot(recall, precision)
fig1=plt.title('DTC')
fig1=plt.show()

roc_auc = roc_auc_score(y_test, y_pred)
print("AUC-PR: %.3f " % auc_precision_recall)
print("ROC AUC: %.3f" % roc_auc)



rfe= RFE(estimator=DecisionTreeClassifier(), n_features_to_select=5)
rfe.fit(X_train_smote, y_train_smote)
y_pred = rfe.predict(X_test)
print(classification_report(y_test,y_pred))

# Data to plot precision - recall curve
precision, recall, thresholds = precision_recall_curve(y_test, y_pred)
# Use AUC function to calculate the area under the curve of precision recall curve
auc_precision_recall = auc(recall, precision)
plt.plot(recall, precision)
fig1=plt.title('DTC')
fig1=plt.show()

roc_auc = roc_auc_score(y_test, y_pred)
print("AUC-PR (SMOTE): %.3f " % auc_precision_recall)
print("ROC AUC (SMOTE): %.3f" % roc_auc)


rfe= RFE(estimator=DecisionTreeClassifier(), n_features_to_select=5)
rfe.fit(X_train_smote_rus, y_train_smote_rus)
y_pred1 = rfe.predict(X_test)
print(classification_report(y_test,y_pred1))

# Data to plot precision - recall curve
precision, recall, thresholds = precision_recall_curve(y_test, y_pred)
# Use AUC function to calculate the area under the curve of precision recall curve
auc_precision_recall = auc(recall, precision)
plt.plot(recall, precision)
fig1=plt.title('DTC')
fig1=plt.show()

roc_auc = roc_auc_score(y_test, y_pred)
print("AUC-PR (SMOTE + RUS): %.3f " % auc_precision_recall)
print("ROC AUC (SMOTE + RUS): %.3f" % roc_auc)

print('Random Forest Algorithm')

rfe= RFE(estimator=RandomForestClassifier(), n_features_to_select=5)
rfe.fit(X_train, y_train)
y_pred = rfe.predict(X_test)
print(classification_report(y_test,y_pred))

# Data to plot precision - recall curve
precision, recall, thresholds = precision_recall_curve(y_test, y_pred)
# Use AUC function to calculate the area under the curve of precision recall curve
auc_precision_recall = auc(recall, precision)
plt.plot(recall, precision)
fig1=plt.title('RFA')
fig1=plt.show()
fig1

roc_auc = roc_auc_score(y_test, y_pred)
print("AUC-PR : %.3f " % auc_precision_recall)
print("ROC AUC : %.3f" % roc_auc)

rfe= RFE(estimator=RandomForestClassifier(), n_features_to_select=5)
rfe.fit(X_train_smote, y_train_smote)
y_pred = rfe.predict(X_test)
print(classification_report(y_test,y_pred))
# Data to plot precision - recall curve
precision, recall, thresholds = precision_recall_curve(y_test, y_pred)
# Use AUC function to calculate the area under the curve of precision recall curve
auc_precision_recall = auc(recall, precision)
plt.plot(recall, precision)
fig1=plt.title('RFA with SMOTE')
fig1=plt.show()
fig1

roc_auc = roc_auc_score(y_test, y_pred)
print("AUC-PR (SMOTE) : %.3f " % auc_precision_recall)
print("ROC AUC (SMOTE): %.3f" % roc_auc)

rfe= RFE(estimator=RandomForestClassifier(), n_features_to_select=5)
rfe.fit(X_train_smote_rus, y_train_smote_rus)
y_pred = rfe.predict(X_test)
print(classification_report(y_test,y_pred))
# Data to plot precision - recall curve
precision, recall, thresholds = precision_recall_curve(y_test, y_pred)
# Use AUC function to calculate the area under the curve of precision recall curve
auc_precision_recall = auc(recall, precision)
print("AUC-PR (SMOTE + RUS): %.3f " % auc_precision_recall)
plt.plot(recall, precision)
fig1=plt.title('RFA with SMOTE + RUS')
fig1=plt.show()
fig1

roc_auc = roc_auc_score(y_test, y_pred)
print("AUC-PR (SMOTE + RUS) : %.3f " % auc_precision_recall)
print("ROC AUC (SMOTE + RUS): %.3f" % roc_auc)

print('XGBoost - RFE')

rfe= RFE(estimator=GradientBoostingClassifier(), n_features_to_select=5)
rfe.fit(X_train, y_train)
y_pred = rfe.predict(X_test)
print(classification_report(y_test,y_pred))

# Data to plot precision - recall curve
precision, recall, thresholds = precision_recall_curve(y_test, y_pred)
# Use AUC function to calculate the area under the curve of precision recall curve
auc_precision_recall = auc(recall, precision)
plt.plot(recall, precision)
fig1=plt.title('RFA')
fig1=plt.show()
fig1

roc_auc = roc_auc_score(y_test, y_pred)
print("AUC-PR : %.3f " % auc_precision_recall)
print("ROC AUC : %.3f" % roc_auc)



rfe= RFE(estimator=GradientBoostingClassifier(), n_features_to_select=5)
rfe.fit(X_train_smote, y_train_smote)
y_pred = rfe.predict(X_test)
print(classification_report(y_test,y_pred))

# Data to plot precision - recall curve
precision, recall, thresholds = precision_recall_curve(y_test, y_pred)
# Use AUC function to calculate the area under the curve of precision recall curve
auc_precision_recall = auc(recall, precision)
plt.plot(recall, precision)
fig1=plt.title('RFA')
fig1=plt.show()
fig1

roc_auc = roc_auc_score(y_test, y_pred)
print("AUC-PR (SMOTE): %.3f " % auc_precision_recall)
print("ROC AUC (SMOTE): %.3f" % roc_auc)



rfe= RFE(estimator=GradientBoostingClassifier(), n_features_to_select=5)
rfe.fit(X_train_smote_rus, y_train_smote_rus)
y_pred = rfe.predict(X_test)
print(classification_report(y_test,y_pred))

# Data to plot precision - recall curve
precision, recall, thresholds = precision_recall_curve(y_test, y_pred)
# Use AUC function to calculate the area under the curve of precision recall curve
auc_precision_recall = auc(recall, precision)
plt.plot(recall, precision)
fig1=plt.title('RFA')
fig1=plt.show()
fig1

roc_auc = roc_auc_score(y_test, y_pred)
print("AUC-PR (SMOTE+RUS) : %.3f " % auc_precision_recall)
print("ROC AUC (SMOTE +RUS): %.3f" % roc_auc)

rfe= RFE(estimator=KNeighborsClassifier(), n_features_to_select=5)
rfe.fit(X_train, y_train)
y_pred = rfe.predict(X_test)
print(classification_report(y_test,y_pred))

# Data to plot precision - recall curve
precision, recall, thresholds = precision_recall_curve(y_test, y_pred)
# Use AUC function to calculate the area under the curve of precision recall curve
auc_precision_recall = auc(recall, precision)
plt.plot(recall, precision)
fig1=plt.title('RFA')
fig1=plt.show()
fig1

roc_auc = roc_auc_score(y_test, y_pred)
print("AUC-PR : %.3f " % auc_precision_recall)
print("ROC AUC : %.3f" % roc_auc)

rfe= RFE(estimator=KNeighborsClassifier(), n_features_to_select=5)
rfe.fit(X_train_smote, y_train_smote)
y_pred = rfe.predict(X_test)
print(classification_report(y_test,y_pred))

# Data to plot precision - recall curve
precision, recall, thresholds = precision_recall_curve(y_test, y_pred)
# Use AUC function to calculate the area under the curve of precision recall curve
auc_precision_recall = auc(recall, precision)
plt.plot(recall, precision)
fig1=plt.title('RFA')
fig1=plt.show()
fig1

roc_auc = roc_auc_score(y_test, y_pred)
print("AUC-PR : %.3f " % auc_precision_recall)
print("ROC AUC : %.3f" % roc_auc)

rfe= RFE(estimator=KNeighborsClassifier(), n_features_to_select=5)
rfe.fit(X_train_smote_rus, y_train_smote_rus)
y_pred = rfe.predict(X_test)
print(classification_report(y_test,y_pred))

# Data to plot precision - recall curve
precision, recall, thresholds = precision_recall_curve(y_test, y_pred)
# Use AUC function to calculate the area under the curve of precision recall curve
auc_precision_recall = auc(recall, precision)
plt.plot(recall, precision)
fig1=plt.title('RFA')
fig1=plt.show()
fig1

roc_auc = roc_auc_score(y_test, y_pred)
print("AUC-PR : %.3f " % auc_precision_recall)
print("ROC AUC : %.3f" % roc_auc)